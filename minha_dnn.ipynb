{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import tensorflow as tf\n",
    "from keras.models import Model#Sequential, Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "#from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import MaxPooling2D, Conv2D\n",
    "#from keras.utils import np_utils\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation, Conv2DTranspose, Input, concatenate, Cropping2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, load_model\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from keras import optimizers\n",
    "\n",
    "from ParamConfig import *\n",
    "from PathConfig import *\n",
    "from LibConfig import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "georec1\n",
      "vmodel1\n",
      "georec2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/skimage/util/shape.py:93: RuntimeWarning: Cannot provide views on a non-contiguous input array without copying.\n",
      "  warn(RuntimeWarning(\"Cannot provide views on a non-contiguous input \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmodel2\n",
      "georec3\n",
      "vmodel3\n",
      "georec4\n",
      "vmodel4\n",
      "georec5\n",
      "vmodel5\n",
      "georec6\n",
      "vmodel6\n",
      "georec7\n",
      "vmodel7\n",
      "georec8\n",
      "vmodel8\n",
      "georec9\n",
      "vmodel9\n",
      "georec10\n",
      "vmodel10\n",
      "georec11\n",
      "vmodel11\n",
      "georec12\n",
      "vmodel12\n",
      "georec13\n",
      "vmodel13\n",
      "georec14\n",
      "vmodel14\n",
      "georec15\n",
      "vmodel15\n",
      "georec16\n",
      "vmodel16\n",
      "georec17\n",
      "vmodel17\n",
      "georec18\n",
      "vmodel18\n",
      "georec19\n",
      "vmodel19\n",
      "georec20\n",
      "vmodel20\n",
      "georec21\n",
      "vmodel21\n",
      "georec22\n",
      "vmodel22\n",
      "georec23\n",
      "vmodel23\n",
      "georec24\n",
      "vmodel24\n",
      "georec25\n",
      "vmodel25\n",
      "georec26\n",
      "vmodel26\n",
      "georec27\n",
      "vmodel27\n",
      "georec28\n",
      "vmodel28\n",
      "georec29\n",
      "vmodel29\n",
      "georec30\n",
      "vmodel30\n",
      "georec31\n",
      "vmodel31\n",
      "georec32\n",
      "vmodel32\n",
      "georec33\n",
      "vmodel33\n",
      "georec34\n",
      "vmodel34\n",
      "georec35\n",
      "vmodel35\n",
      "georec36\n",
      "vmodel36\n",
      "georec37\n",
      "vmodel37\n",
      "georec38\n",
      "vmodel38\n",
      "georec39\n",
      "vmodel39\n",
      "georec40\n",
      "vmodel40\n",
      "georec41\n",
      "vmodel41\n",
      "georec42\n",
      "vmodel42\n",
      "georec43\n",
      "vmodel43\n",
      "georec44\n",
      "vmodel44\n",
      "georec45\n",
      "vmodel45\n",
      "georec46\n",
      "vmodel46\n",
      "georec47\n",
      "vmodel47\n",
      "georec48\n",
      "vmodel48\n",
      "georec49\n",
      "vmodel49\n",
      "georec50\n",
      "vmodel50\n",
      "georec51\n",
      "vmodel51\n",
      "georec52\n",
      "vmodel52\n",
      "georec53\n",
      "vmodel53\n",
      "georec54\n",
      "vmodel54\n",
      "georec55\n",
      "vmodel55\n",
      "georec56\n",
      "vmodel56\n",
      "georec57\n",
      "vmodel57\n",
      "georec58\n",
      "vmodel58\n",
      "georec59\n",
      "vmodel59\n",
      "georec60\n",
      "vmodel60\n",
      "georec61\n",
      "vmodel61\n",
      "georec62\n",
      "vmodel62\n",
      "georec63\n",
      "vmodel63\n",
      "georec64\n",
      "vmodel64\n",
      "georec65\n",
      "vmodel65\n",
      "georec66\n",
      "vmodel66\n",
      "georec67\n",
      "vmodel67\n",
      "georec68\n",
      "vmodel68\n",
      "georec69\n",
      "vmodel69\n",
      "georec70\n",
      "vmodel70\n",
      "georec71\n",
      "vmodel71\n",
      "georec72\n",
      "vmodel72\n",
      "georec73\n",
      "vmodel73\n",
      "georec74\n",
      "vmodel74\n",
      "georec75\n",
      "vmodel75\n",
      "georec76\n",
      "vmodel76\n",
      "georec77\n",
      "vmodel77\n",
      "georec78\n",
      "vmodel78\n",
      "georec79\n",
      "vmodel79\n",
      "georec80\n",
      "vmodel80\n",
      "georec81\n",
      "vmodel81\n",
      "georec82\n",
      "vmodel82\n",
      "georec83\n",
      "vmodel83\n",
      "georec84\n",
      "vmodel84\n",
      "georec85\n",
      "vmodel85\n",
      "georec86\n",
      "vmodel86\n",
      "georec87\n",
      "vmodel87\n",
      "georec88\n",
      "vmodel88\n",
      "georec89\n",
      "vmodel89\n",
      "georec90\n",
      "vmodel90\n",
      "georec91\n",
      "vmodel91\n",
      "georec92\n",
      "vmodel92\n",
      "georec93\n",
      "vmodel93\n",
      "georec94\n",
      "vmodel94\n",
      "georec95\n",
      "vmodel95\n",
      "georec96\n",
      "vmodel96\n",
      "georec97\n",
      "vmodel97\n",
      "georec98\n",
      "vmodel98\n",
      "georec99\n",
      "vmodel99\n",
      "georec100\n",
      "vmodel100\n",
      "georec101\n",
      "vmodel101\n",
      "georec102\n",
      "vmodel102\n",
      "georec103\n",
      "vmodel103\n",
      "georec104\n",
      "vmodel104\n",
      "georec105\n",
      "vmodel105\n",
      "georec106\n",
      "vmodel106\n",
      "georec107\n",
      "vmodel107\n",
      "georec108\n",
      "vmodel108\n",
      "georec109\n",
      "vmodel109\n",
      "georec110\n",
      "vmodel110\n",
      "georec111\n",
      "vmodel111\n",
      "georec112\n",
      "vmodel112\n",
      "georec113\n",
      "vmodel113\n",
      "georec114\n",
      "vmodel114\n",
      "georec115\n",
      "vmodel115\n",
      "georec116\n",
      "vmodel116\n",
      "georec117\n",
      "vmodel117\n",
      "georec118\n",
      "vmodel118\n",
      "georec119\n",
      "vmodel119\n",
      "georec120\n",
      "vmodel120\n",
      "georec121\n",
      "vmodel121\n",
      "georec122\n",
      "vmodel122\n",
      "georec123\n",
      "vmodel123\n",
      "georec124\n",
      "vmodel124\n",
      "georec125\n",
      "vmodel125\n",
      "georec126\n",
      "vmodel126\n",
      "georec127\n",
      "vmodel127\n",
      "georec128\n",
      "vmodel128\n",
      "georec129\n",
      "vmodel129\n",
      "georec130\n",
      "vmodel130\n",
      "georec131\n",
      "vmodel131\n",
      "georec132\n",
      "vmodel132\n",
      "georec133\n",
      "vmodel133\n",
      "georec134\n",
      "vmodel134\n",
      "georec135\n",
      "vmodel135\n",
      "georec136\n",
      "vmodel136\n",
      "georec137\n",
      "vmodel137\n",
      "georec138\n",
      "vmodel138\n",
      "georec139\n",
      "vmodel139\n",
      "georec140\n",
      "vmodel140\n",
      "georec141\n",
      "vmodel141\n",
      "georec142\n",
      "vmodel142\n",
      "georec143\n",
      "vmodel143\n",
      "georec144\n",
      "vmodel144\n",
      "georec145\n",
      "vmodel145\n",
      "georec146\n",
      "vmodel146\n",
      "georec147\n",
      "vmodel147\n",
      "georec148\n",
      "vmodel148\n",
      "georec149\n",
      "vmodel149\n",
      "georec150\n",
      "vmodel150\n",
      "georec151\n",
      "vmodel151\n",
      "georec152\n",
      "vmodel152\n",
      "georec153\n",
      "vmodel153\n",
      "georec154\n",
      "vmodel154\n",
      "georec155\n",
      "vmodel155\n",
      "georec156\n",
      "vmodel156\n",
      "georec157\n",
      "vmodel157\n",
      "georec158\n",
      "vmodel158\n",
      "georec159\n",
      "vmodel159\n",
      "georec160\n",
      "vmodel160\n",
      "georec161\n",
      "vmodel161\n",
      "georec162\n",
      "vmodel162\n",
      "georec163\n",
      "vmodel163\n",
      "georec164\n",
      "vmodel164\n",
      "georec165\n",
      "vmodel165\n",
      "georec166\n",
      "vmodel166\n",
      "georec167\n",
      "vmodel167\n",
      "georec168\n",
      "vmodel168\n",
      "georec169\n",
      "vmodel169\n",
      "georec170\n",
      "vmodel170\n",
      "georec171\n",
      "vmodel171\n",
      "georec172\n",
      "vmodel172\n",
      "georec173\n",
      "vmodel173\n",
      "georec174\n",
      "vmodel174\n",
      "georec175\n",
      "vmodel175\n",
      "georec176\n",
      "vmodel176\n",
      "georec177\n",
      "vmodel177\n",
      "georec178\n",
      "vmodel178\n",
      "georec179\n",
      "vmodel179\n",
      "georec180\n",
      "vmodel180\n",
      "georec181\n",
      "vmodel181\n",
      "georec182\n",
      "vmodel182\n",
      "georec183\n",
      "vmodel183\n",
      "georec184\n",
      "vmodel184\n",
      "georec185\n",
      "vmodel185\n",
      "georec186\n",
      "vmodel186\n",
      "georec187\n",
      "vmodel187\n",
      "georec188\n",
      "vmodel188\n",
      "georec189\n",
      "vmodel189\n",
      "georec190\n",
      "vmodel190\n",
      "georec191\n",
      "vmodel191\n",
      "georec192\n",
      "vmodel192\n",
      "georec193\n",
      "vmodel193\n",
      "georec194\n",
      "vmodel194\n",
      "georec195\n",
      "vmodel195\n",
      "georec196\n",
      "vmodel196\n",
      "georec197\n",
      "vmodel197\n",
      "georec198\n",
      "vmodel198\n",
      "georec199\n",
      "vmodel199\n",
      "georec200\n",
      "vmodel200\n"
     ]
    }
   ],
   "source": [
    "X_train,Y_train  = DataLoad_Train(train_size=190,train_data_dir=train_data_dir, \\\n",
    "                                                                 data_dim=DataDim,in_channels=Inchannels, \\\n",
    "                                                                 model_dim=ModelDim,data_dsp_blk=data_dsp_blk, \\\n",
    "                                                                 label_dsp_blk=label_dsp_blk,start=1, \\\n",
    "                                                                 datafilename=datafilename,dataname=dataname, \\\n",
    "                                                                 truthfilename=truthfilename,truthname=truthname, folder_dataset=folder_dataset)\n",
    "# Change data type (numpy --> tensor)\n",
    "\n",
    "\n",
    "X_test,Y_test  = DataLoad_Test(train_size=TrainSize,train_data_dir=train_data_dir, \\\n",
    "                                                                 data_dim=DataDim,in_channels=Inchannels, \\\n",
    "                                                                 model_dim=ModelDim,data_dsp_blk=data_dsp_blk, \\\n",
    "                                                                 label_dsp_blk=label_dsp_blk,start=1, \\\n",
    "                                                                 datafilename=datafilename,dataname=dataname, \\\n",
    "                                                                 truthfilename=truthfilename,truthname=truthname, folder_dataset=folder_dataset)\n",
    "# Change data type (numpy --> tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 400, 304, 29) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 400, 304, 64) 16768       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 400, 304, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 400, 304, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 400, 304, 64) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 400, 304, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 400, 304, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 200, 152, 64) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 200, 152, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200, 152, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 200, 152, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 200, 152, 128 147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200, 152, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 152, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 100, 76, 128) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 100, 76, 256) 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 76, 256) 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100, 76, 256) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 100, 76, 256) 590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 76, 256) 1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 76, 256) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 50, 38, 256)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 50, 38, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 38, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 50, 38, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 50, 38, 512)  2359808     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 50, 38, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 50, 38, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 25, 19, 512)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 19, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 19, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 19, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 19, 1024) 9438208     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 19, 1024) 4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 19, 1024) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 50, 38, 512)  2097664     activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 38, 1024) 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 50, 38, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 50, 38, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 50, 38, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 50, 38, 512)  2359808     activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 50, 38, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 50, 38, 512)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 100, 76, 256) 524544      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100, 76, 512) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 100, 76, 256) 1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 100, 76, 256) 1024        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100, 76, 256) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 100, 76, 256) 590080      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 100, 76, 256) 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 100, 76, 256) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 200, 152, 128 131200      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 200, 152, 256 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 200, 152, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 200, 152, 128 512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 200, 152, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 200, 152, 128 147584      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 200, 152, 128 512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 200, 152, 128 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 400, 304, 64) 32832       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 400, 304, 128 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 400, 304, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 400, 304, 64) 256         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 400, 304, 64) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 202, 302, 64) 0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 202, 302, 64) 36928       cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 202, 302, 64) 256         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 202, 302, 64) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 202, 302, 1)  65          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 31,070,273\n",
      "Trainable params: 31,058,497\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "linhas=X_train.shape[1]\n",
    "colunas= X_train.shape[2]\n",
    "canais = X_train.shape[3]\n",
    "\n",
    "\n",
    "def apply_maxPooling(camada):\n",
    "    camada = MaxPooling2D(pool_size=(2,2),padding='same') (camada)\n",
    "    return camada\n",
    "\n",
    "def reduzir(camada,out_size):\n",
    "    camada = Conv2D(filters=out_size, kernel_size=(3, 3), input_shape=(linhas, colunas, canais), strides=1, padding='same') (camada)\n",
    "    camada = BatchNormalization() (camada)\n",
    "    camada = Activation('relu') (camada)\n",
    "    \n",
    "    #reaplicando novamente no dado\n",
    "    camada = Conv2D(filters=out_size, kernel_size=(3, 3), input_shape=(linhas, colunas, canais), strides=1, padding='same') (camada)\n",
    "    camada = BatchNormalization() (camada)\n",
    "    camada = Activation('relu') (camada)\n",
    "    \n",
    "    return camada\n",
    "\n",
    "\n",
    "def reduzir_last(camada,out_size):\n",
    "    camada = Conv2D(filters=out_size, kernel_size=(3, 3), input_shape=(linhas, colunas, canais), strides=1, padding='same') (camada)\n",
    "    camada = BatchNormalization() (camada)\n",
    "    camada = Activation('relu') (camada)\n",
    "\n",
    "    return camada\n",
    "\n",
    "def aumentar_last(camada_corrente,camada_de_reducao_correspondente,out_size):\n",
    "    camada = Conv2DTranspose(filters=out_size,kernel_size=(2,2),strides=2,padding='same') (camada_corrente)\n",
    "    camada = concatenate([camada,camada_de_reducao_correspondente],axis=3) #aqui concateno o dado após a deconvolução com o dado correspondente na camada de redução\n",
    "    camada = reduzir_last(camada,out_size)\n",
    "\n",
    "    return camada\n",
    "\n",
    "\n",
    "def aumentar(camada_corrente,camada_de_reducao_correspondente,out_size):\n",
    "    camada = Conv2DTranspose(filters=out_size,kernel_size=(2,2),strides=2,padding='same') (camada_corrente)\n",
    "    camada = concatenate([camada,camada_de_reducao_correspondente],axis=3) #aqui concateno o dado após a deconvolução com o dado correspondente na camada de redução\n",
    "    camada = reduzir(camada,out_size)\n",
    "\n",
    "    return camada\n",
    "\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "\n",
    "#sgd = optimizers.SGD(lr=0.01, clipnorm=1.)\n",
    "\n",
    "\n",
    "def create_model(linhas,colunas,canais):\n",
    "    inputs = Input((linhas,colunas,canais))\n",
    "    \n",
    "    filtros=[64,128,256,512,1024]\n",
    "    c1 = reduzir(inputs,filtros[0])\n",
    "    c2 = reduzir(apply_maxPooling(c1),filtros[1])\n",
    "    c3 = reduzir(apply_maxPooling(c2),filtros[2])\n",
    "    c4 = reduzir(apply_maxPooling(c3),filtros[3])\n",
    "    c5 = reduzir(apply_maxPooling(c4),filtros[4])\n",
    "    \n",
    "\n",
    "    c6 = aumentar(c5,c4,filtros[3])\n",
    "    c7 = aumentar(c6,c3,filtros[2])\n",
    "    c8 = aumentar(c7,c2,filtros[1])\n",
    "    c9 = aumentar_last(c8,c1,filtros[0])\n",
    "    \n",
    "    c9 = Cropping2D(cropping=(99, 1)) (c9) #fiz um crop na imagem que era (400,304) e deixei com (202,302)\n",
    "    c9 = reduzir_last(c9,filtros[0])\n",
    "    c9 = Conv2D(filters=1, kernel_size=(1, 1), strides=1) (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs],outputs=[c9])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = create_model(linhas,colunas,canais)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jonas/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 171 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "171/171 [==============================] - 36s 210ms/step - loss: 2.8613 - mse: 2.8613 - val_loss: 1467759.7171 - val_mse: 1467759.7500\n",
      "Epoch 2/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.1805 - mse: 0.1805 - val_loss: 51.3935 - val_mse: 51.3935\n",
      "Epoch 3/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0605 - mse: 0.0605 - val_loss: 2.7235 - val_mse: 2.7235\n",
      "Epoch 4/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0449 - mse: 0.0449 - val_loss: 1.6757 - val_mse: 1.6757\n",
      "Epoch 5/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0397 - mse: 0.0397 - val_loss: 1.1128 - val_mse: 1.1128\n",
      "Epoch 6/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.8258 - val_mse: 0.8258\n",
      "Epoch 7/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.7198 - val_mse: 0.7198\n",
      "Epoch 8/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0349 - mse: 0.0349 - val_loss: 0.6725 - val_mse: 0.6725\n",
      "Epoch 9/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.4079 - val_mse: 0.4079\n",
      "Epoch 10/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.4696 - val_mse: 0.4696\n",
      "Epoch 11/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.3315 - val_mse: 0.3315\n",
      "Epoch 12/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.2387 - val_mse: 0.2387\n",
      "Epoch 13/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.1737 - val_mse: 0.1737\n",
      "Epoch 14/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.0333 - val_mse: 0.0333\n",
      "Epoch 15/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.1923 - val_mse: 0.1923\n",
      "Epoch 16/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0262 - mse: 0.0262 - val_loss: 0.2139 - val_mse: 0.2139\n",
      "Epoch 17/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.0679 - val_mse: 0.0679\n",
      "Epoch 18/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.2384 - val_mse: 0.2384\n",
      "Epoch 19/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.0179 - val_mse: 0.0179\n",
      "Epoch 20/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.0297 - val_mse: 0.0297\n",
      "Epoch 21/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.1231 - val_mse: 0.1231\n",
      "Epoch 22/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.1412 - val_mse: 0.1412\n",
      "Epoch 23/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.1756 - val_mse: 0.1756\n",
      "Epoch 24/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.1374 - val_mse: 0.1374\n",
      "Epoch 25/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.2581 - val_mse: 0.2581\n",
      "Epoch 26/100\n",
      "171/171 [==============================] - 24s 140ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0276 - val_mse: 0.0276\n",
      "Epoch 27/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0854 - val_mse: 0.0854\n",
      "Epoch 28/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 29/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0551 - val_mse: 0.0551\n",
      "Epoch 30/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0160 - mse: 0.0160 - val_loss: 0.0991 - val_mse: 0.0991\n",
      "Epoch 31/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0156 - val_mse: 0.0156\n",
      "Epoch 32/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0320 - val_mse: 0.0320\n",
      "Epoch 33/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 34/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0153 - mse: 0.0153 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 35/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0156 - mse: 0.0156 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 36/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0158 - mse: 0.0158 - val_loss: 0.0422 - val_mse: 0.0422\n",
      "Epoch 37/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0146 - mse: 0.0146 - val_loss: 0.0342 - val_mse: 0.0342\n",
      "Epoch 38/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0338 - val_mse: 0.0338\n",
      "Epoch 39/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0143 - mse: 0.0143 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 40/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0147 - mse: 0.0147 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 41/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0141 - mse: 0.0141 - val_loss: 0.0164 - val_mse: 0.0164\n",
      "Epoch 42/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0149 - mse: 0.0149 - val_loss: 0.0273 - val_mse: 0.0273\n",
      "Epoch 43/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0303 - val_mse: 0.0303\n",
      "Epoch 44/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0138 - mse: 0.0138 - val_loss: 0.0266 - val_mse: 0.0266\n",
      "Epoch 45/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0203 - val_mse: 0.0203\n",
      "Epoch 46/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0134 - mse: 0.0134 - val_loss: 0.0162 - val_mse: 0.0162\n",
      "Epoch 47/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0133 - mse: 0.0133 - val_loss: 0.0473 - val_mse: 0.0473\n",
      "Epoch 48/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0139 - mse: 0.0139 - val_loss: 0.0185 - val_mse: 0.0185\n",
      "Epoch 49/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0140 - mse: 0.0140 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 50/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 51/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 52/100\n",
      "171/171 [==============================] - 26s 150ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 53/100\n",
      "171/171 [==============================] - 27s 158ms/step - loss: 0.0128 - mse: 0.0128 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 54/100\n",
      "171/171 [==============================] - 24s 142ms/step - loss: 0.0132 - mse: 0.0132 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 55/100\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.0130 - mse: 0.0130 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 56/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0126 - mse: 0.0126 - val_loss: 0.0207 - val_mse: 0.0207\n",
      "Epoch 57/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0129 - mse: 0.0129 - val_loss: 0.0155 - val_mse: 0.0155\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0124 - mse: 0.0124 - val_loss: 0.0137 - val_mse: 0.0137\n",
      "Epoch 59/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0218 - val_mse: 0.0218\n",
      "Epoch 60/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0183 - val_mse: 0.0183\n",
      "Epoch 61/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 62/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0115 - mse: 0.0115 - val_loss: 0.0130 - val_mse: 0.0130\n",
      "Epoch 63/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0123 - mse: 0.0123 - val_loss: 0.0146 - val_mse: 0.0146\n",
      "Epoch 64/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0118 - mse: 0.0118 - val_loss: 0.0145 - val_mse: 0.0145\n",
      "Epoch 65/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0121 - mse: 0.0121 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 66/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0202 - val_mse: 0.0202\n",
      "Epoch 67/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 68/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 69/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0149 - val_mse: 0.0149\n",
      "Epoch 70/100\n",
      "171/171 [==============================] - 28s 164ms/step - loss: 0.0120 - mse: 0.0120 - val_loss: 0.0173 - val_mse: 0.0173\n",
      "Epoch 71/100\n",
      "171/171 [==============================] - 26s 151ms/step - loss: 0.0119 - mse: 0.0119 - val_loss: 0.0205 - val_mse: 0.0205\n",
      "Epoch 72/100\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.0116 - mse: 0.0116 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 73/100\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 74/100\n",
      "171/171 [==============================] - 25s 145ms/step - loss: 0.0109 - mse: 0.0109 - val_loss: 0.0277 - val_mse: 0.0277\n",
      "Epoch 75/100\n",
      "171/171 [==============================] - 24s 142ms/step - loss: 0.0122 - mse: 0.0122 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 76/100\n",
      "171/171 [==============================] - 24s 141ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0209 - val_mse: 0.0209\n",
      "Epoch 77/100\n",
      "171/171 [==============================] - 24s 140ms/step - loss: 0.0108 - mse: 0.0108 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 78/100\n",
      "171/171 [==============================] - 24s 142ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0140 - val_mse: 0.0140\n",
      "Epoch 79/100\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 80/100\n",
      "171/171 [==============================] - 27s 159ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 81/100\n",
      "171/171 [==============================] - 25s 149ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 82/100\n",
      "171/171 [==============================] - 27s 156ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 83/100\n",
      "171/171 [==============================] - 25s 145ms/step - loss: 0.0111 - mse: 0.0111 - val_loss: 0.0167 - val_mse: 0.0167\n",
      "Epoch 84/100\n",
      "171/171 [==============================] - 25s 147ms/step - loss: 0.0125 - mse: 0.0125 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 85/100\n",
      "171/171 [==============================] - 25s 149ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0188 - val_mse: 0.0188\n",
      "Epoch 86/100\n",
      "171/171 [==============================] - 25s 146ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0194 - val_mse: 0.0194\n",
      "Epoch 87/100\n",
      "171/171 [==============================] - 25s 148ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0181 - val_mse: 0.0181\n",
      "Epoch 88/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 89/100\n",
      "171/171 [==============================] - 24s 138ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0144 - val_mse: 0.0144\n",
      "Epoch 90/100\n",
      "171/171 [==============================] - 24s 140ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0204 - val_mse: 0.0204\n",
      "Epoch 91/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0170 - val_mse: 0.0170\n",
      "Epoch 92/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0172 - val_mse: 0.0172\n",
      "Epoch 93/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0201 - val_mse: 0.0201\n",
      "Epoch 94/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 95/100\n",
      "171/171 [==============================] - 23s 135ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 96/100\n",
      "171/171 [==============================] - 23s 137ms/step - loss: 0.0104 - mse: 0.0104 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 97/100\n",
      "171/171 [==============================] - 24s 140ms/step - loss: 0.0105 - mse: 0.0105 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 98/100\n",
      "171/171 [==============================] - 23s 136ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 99/100\n",
      "171/171 [==============================] - 25s 144ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0139 - val_mse: 0.0139\n",
      "Epoch 100/100\n",
      "171/171 [==============================] - 24s 139ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0140 - val_mse: 0.0140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9fc4243d68>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "#from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "#earlystopper = EarlyStopping(patience=10, verbose=1)\n",
    "#checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "#ReduceLROnPlateau = ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1)\n",
    "#model.fit(X_train, Y_train, validation_split=0.1, batch_size=5, epochs=10, \n",
    "#                    callbacks=[earlystopper])\n",
    "\n",
    "model.fit(X_train, Y_train, validation_split=0.1, batch_size=5, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "# callbacks = [\n",
    "#     EarlyStopping(patience=10, verbose=1),\n",
    "#     ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.001, verbose=1),\n",
    "#     ModelCheckpoint('model-tgs-salt.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "# ]\n",
    "# results = model.fit(X_train, Y_train, batch_size=5, epochs=50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvando modelo 1\n",
      "Salvando modelo 2\n",
      "Salvando modelo 3\n",
      "Salvando modelo 4\n",
      "Salvando modelo 5\n",
      "Salvando modelo 6\n",
      "Salvando modelo 7\n",
      "Salvando modelo 8\n",
      "Salvando modelo 9\n",
      "Salvando modelo 10\n"
     ]
    }
   ],
   "source": [
    "def generate_predicoes(predicoes,Y_test):\n",
    "    for i in range(0,predicoes.shape[0]):\n",
    "        print ('Salvando modelo '+ str(i+1))\n",
    "        #imprimindo o modelo de velocidade real\n",
    "        vmodel = Y_test[i];\n",
    "        vmodel = vmodel.reshape(202,302)\n",
    "        sio.savemat('vmodel'+str(i)+'.mat',{'vmodel': vmodel})\n",
    "        \n",
    "        #imprimindo o modelo de velocidade predito\n",
    "        vmodel = predicoes[i];\n",
    "        vmodel = vmodel.reshape(202,302)\n",
    "        sio.savemat('predito'+str(i)+'.mat',{'vmodel': vmodel})\n",
    "\n",
    "generate_predicoes(preds_test,Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
